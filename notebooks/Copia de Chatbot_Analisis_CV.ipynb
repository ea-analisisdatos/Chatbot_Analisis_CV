{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1a3Ld5PvR_g6Led76t8HMhAEy_fcfAmo7","authorship_tag":"ABX9TyPjNzt2t/Vv7vNFi5ReeqXy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"QQTUxJbRo2Nj"}},{"cell_type":"markdown","source":["# **Proyecto: Chatbot de An√°lisis de Curr√≠culum Vitae**\n","\n","## **Descripci√≥n**\n","El objetivo de este proyecto es desarrollar un chatbot que permita subir curr√≠culums en diferentes formatos (PDF, DOCX, TXT, HTML), analizar su contenido y responder a preguntas relacionadas con habilidades, experiencia, localizaci√≥n y otros detalles relevantes. Este proyecto usar√° herramientas de c√≥digo abierto y gratuitas para garantizar accesibilidad y aprendizaje."],"metadata":{"id":"w253QQTHo6kH"}},{"cell_type":"markdown","source":["\n","\n","### **Plan del Proyecto: Chatbot de An√°lisis de Curr√≠culum Vitae**\n","\n","#### **1. Requisitos del Proyecto**\n","- **Entrada**: Subir curr√≠culums en formatos como PDF, DOCX, TXT o HTML.\n","- **Procesamiento**: Extraer texto de los documentos y estructurar los datos relevantes.\n","- **Salida**: Responder a preguntas basadas en las habilidades, experiencia, ubicaci√≥n y otros detalles de los candidatos.\n","- **Almacenamiento**: Decidiremos entre bases de datos vectoriales (para b√∫squedas sem√°nticas) o bases relacionales.\n","- **Tecnolog√≠as**:\n","  - Preprocesamiento de documentos: `PyPDF2`, `python-docx`, `BeautifulSoup`.\n","  - Modelo de lenguaje gratuito: `Hugging Face` (ej. `Llama 2` o `distilbert`).\n","  - Framework para la aplicaci√≥n: `Streamlit` para despliegue en Google Colab.\n","  - Almacenamiento vectorial: `FAISS` o `Chroma`.\n","\n","---\n","\n","## **Fases del Proyecto**\n","\n","---\n","\n","#### **2. Fases del Desarrollo**\n","##### **Fase 1: Configuraci√≥n Inicial**\n","1. Crear repositorio en Github para almacenar el proyecto.\n","2. Crear la Estructura de Carpetas del Proyecto en Google Drive.\n","3. Crear un entorno en **Google Colab**.\n","4. Instalar las bibliotecas necesarias:\n","  - ***PyPDF2:*** para extraer texto de PDFs.\n","  - ***python-docx:*** para extraer texto de DOCX.\n","  - ***beautifulSoup:*** para extraer texto de HTML.\n","  - ***sentence-transformers:*** para generar embeddings.\n","  - ***faiss-cpu:*** para almacenamiento vectorial.\n","  - ***streamlit:*** para la interfaz gr√°fica.\n","  - ***pyngrok:*** para desplegar la aplicaci√≥n.\n","\n","5. Crear un script que permita subir archivos y extraer texto.\n","\n","---\n","\n","##### **Fase 2: Procesamiento de Documentos**\n","1. **Subir archivos**: Permitir la carga de archivos en diferentes formatos\n","  - Usar el widget de carga de archivos en Streamlit para recibir documentos del usuario.\n","  - Extraer texto de archivos PDF, DOCX, TXT y HTML:\n","    - Usar `PyPDF2` para PDFs.\n","    - Usar `python-docx` para DOCX.\n","    - Usar `BeautifulSoup` para HTML.\n","  - **Limpieza del texto**:\n","    - Limpiar y estructurar el texto extra√≠do.\n","    - Eliminar caracteres innecesarios y estructurar el texto para su an√°lisis.\n","---\n","\n","##### **Fase 3: Vectorizaci√≥n del Texto**\n","1. Convertir el texto en ***representaciones vectoriales*** utilizando modelos de Hugging Face.\n","  - Usar un modelo preentrenado de Hugging Face (como `all-MiniLM-L6-v2`):\n","   ```python\n","   from sentence_transformers import SentenceTransformer\n","   model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n","   embeddings = model.encode([\"Texto del documento\"])\n","   ```\n","2. **Almacenamiento vectorial**:\n","   - Almacenar los embeddings usando **FAISS** para realizar b√∫squedas r√°pidas. - Analisar el almacenamiento con **Chroma** caso no funcione con **FAISS**.\n","\n","---\n","\n","##### **Fase 4: Creaci√≥n del Chatbot**\n","1. Implementar una **interfaz gr√°fica** usando **Streamlit**:\n","2. Permitir al usuario escribir preguntas y obtener respuestas basadas en los embeddings.\n","3. Consultar los embeddings y devolver respuestas basadas en las consultas.\n","\n","---\n","\n","##### **Fase 5: Despliegue en Google Colab**\n","1. **Configurar Streamlit** para ejecutarse dentro de Google Colab:\n","   - Usar `pyngrok` para generar un enlace p√∫blico a la aplicaci√≥n.\n","2. **Realizar pruebas funcionales:** Realizar pruebas funcionales y verificar el correcto funcionamiento del chatbot.\n","  - Validar que las librer√≠as seleccionadas (como BeautifulSoup) son suficientes para procesar los documentos en HTML.\n","3. **Funcionalidades Avanzadas:**\n","  - Agregar funcionalidades avanzadas como clasificaci√≥n autom√°tica de candidatos y extracci√≥n de datos m√°s compleja.\n","  - Implementar m√©tricas de evaluaci√≥n para medir la precisi√≥n de las respuestas del chatbot.\n","4. **Optimizaci√≥n y Seguridad:**\n","  - Optimizar el flujo de trabajo para un entorno de producci√≥n.\n","  - Considerar aspectos de seguridad para el despliegue del chatbot.\n","\n","\n","---\n","\n","## **Herramientas Utilizadas**\n","- **Preprocesamiento de documentos**:\n","  - `PyPDF2`: Para extraer texto de PDFs.\n","  - `python-docx`: Para extraer texto de archivos DOCX.\n","  - `BeautifulSoup`: Para procesar HTML.\n","- **Modelos de lenguaje**:\n","  - `Hugging Face`: Modelos como `all-MiniLM-L6-v2`.\n","- **Almacenamiento vectorial**:\n","  - `FAISS` o `Chroma`.\n","  - `FAISS`: Para b√∫squedas eficientes.\n","- **Framework de desarrollo**:\n","  - `Streamlit`: Para crear la interfaz del usuario.\n","- **Entorno**:\n","  - Google Colab como plataforma de desarrollo y pruebas.\n","\n","---\n","\n","#### **3. Pr√≥ximos Pasos**\n","\n","1. **Funcionalidades Avanzadas:**\n","  - Uso de ***bases de datos relacionales*** para almacenar informaci√≥n adicional de los candidatos.\n","  - ***Clasificaci√≥n autom√°tica de candidatos*** seg√∫n criterios predefinidos.\n","  - Extracci√≥n de datos m√°s compleja (por ejemplo, ***identificar autom√°ticamente a√±os de experiencia laboral o idiomas***).\n","2. **Mejora del Chatbot:**\n","  - Mejorar la capacidad del chatbot para realizar ***inferencias m√°s complejas***.\n","  - ***Implementar m√©tricas de evaluaci√≥n*** para medir la precisi√≥n de las respuestas del chatbot.\n","3. **Soporte para Im√°genes:**\n","  - Permitir la carga de ***curr√≠culums en formato de imagen*** utilizando OCR(Reconocimiento √ìptico de Caracteres (OCR)).\n","4. **Optimizaci√≥n para Producci√≥n:**\n","  - Optimizar el flujo de trabajo para un entorno de producci√≥n.\n","\n","---\n","\n","## **Notas**\n","\n","Este proyecto es una introducci√≥n pr√°ctica al uso de herramientas de procesamiento de lenguaje natural, con √©nfasis en el aprendizaje y la accesibilidad.<br>\n","\n","Est√° dise√±ado para ser educativo y funcional, proporcionando una base s√≥lida para aprender sobre procesamiento de documentos, embeddings y construcci√≥n de chatbots. üòä"],"metadata":{"id":"GQ-tcFJYreOj"}},{"cell_type":"markdown","source":["## Estructura de Carpetas del Proyecto `Chatbot_Analisis_CV`\n"],"metadata":{"id":"-DDnncaLeuNk"}},{"cell_type":"markdown","source":["## Descripci√≥n de Carpetas\n","\n","```\n","Chatbot_Analisis_CV/\n","‚îÇ\n","‚îú‚îÄ‚îÄ data/                 # Para almacenar datasets y documentos de entrada\n","‚îÇ   ‚îú‚îÄ‚îÄ input/            # Archivos originales, como CVs en formatos PDF, DOCX, etc.\n","‚îÇ   ‚îî‚îÄ‚îÄ processed/        # Archivos procesados (texto extra√≠do, embeddings, etc.)\n","‚îÇ\n","‚îú‚îÄ‚îÄ embeddings/           # Para almacenar archivos de embeddings generados\n","‚îÇ\n","‚îú‚îÄ‚îÄ scripts/              # Scripts Python utilizados en el proyecto\n","‚îÇ   ‚îú‚îÄ‚îÄ preprocess/       # Scripts de preprocesamiento (extracci√≥n de texto, limpieza)\n","‚îÇ   ‚îú‚îÄ‚îÄ vectorization/    # Scripts para generar y manejar embeddings\n","‚îÇ   ‚îî‚îÄ‚îÄ chatbot/          # Scripts relacionados con la interfaz del chatbot\n","‚îÇ\n","‚îú‚îÄ‚îÄ notebooks/            # Notebooks de desarrollo y an√°lisis\n","‚îÇ\n","‚îú‚îÄ‚îÄ models/               # Modelos guardados (si es necesario entrenar alguno)\n","‚îÇ\n","‚îî‚îÄ‚îÄ logs/                 # Archivos de registro para guardar errores o procesos\n","```\n","\n"],"metadata":{"id":"3JbpnZcsfL64"}},{"cell_type":"markdown","source":["## ‚öôÔ∏è **Configuraci√≥n del Ambiente e Importaci√≥n de Datos**<a name=\"configuracion-del-ambiente\"></a>\n","\n","En esta secci√≥n, se hace la Configuraci√≥n Inicial del Ambiente de Trabajo.\n","- Se importan las bibliotecas necesarias para trabajar en el proyecto.\n","- Configuramos el entorno para visualizar todas las columnas de la tabla sin que la informaci√≥n se corte.\n","- Tambi√©n habilitamos el acceso a Google Drive para la lectura del archivo CSV y, finalmente, importamos y organizamos el conjunto de datos."],"metadata":{"id":"N-PoUrMx7_P4"}},{"cell_type":"markdown","source":["### ‚úîÔ∏èInstalar las bibliotecas necesarias<a name=\"instalar-las-bibliotecas-necesarias\"></a>"],"metadata":{"id":"SrYNKOPZWcUR"}},{"cell_type":"code","source":["%%time\n","import sys\n","import subprocess\n","from importlib.metadata import version, PackageNotFoundError\n","\n","# Lista de librer√≠as requeridas para el proyecto\n","required_libraries = [\n","    'pypdf2',             # Para extraer texto de archivos PDF\n","    'python-docx',        # Para procesar archivos DOCX\n","    'beautifulsoup4',     # Para analizar archivos HTML\n","    'sentence-transformers', # Para generar embeddings\n","    'faiss-cpu',          # Para almacenamiento vectorial\n","    'streamlit',          # Para la interfaz gr√°fica\n","    'pyngrok',            # Added pyngrok to the list of required libraries\n","    'google-colab-user-data'\n","]\n","\n","# Funci√≥n para instalar librer√≠as de Python faltantes\n","def install_libraries(libraries):\n","    for lib in libraries:\n","        try:\n","            print(f\"Instalando {lib}...\")\n","            subprocess.check_call([sys.executable, '-m', 'pip', 'install', lib])\n","        except Exception as e:\n","            print(f\"Error instalando {lib}: {e}\")\n","\n","# Instalar librer√≠as requeridas\n","install_libraries(required_libraries)\n","\n","# Instalar localtunnel usando npm\n","!apt-get install -y nodejs npm\n","!npm install -g localtunnel\n","\n","# Imprimir las versiones de las librer√≠as instaladas\n","print(\"\\nVersiones de las librer√≠as instaladas:\")\n","for lib in required_libraries:\n","    try:\n","        print(f\"{lib}: {version(lib)}\")\n","    except PackageNotFoundError:\n","        print(f\"{lib}: No instalado\")\n","\n","# Verificar la instalaci√≥n de localtunnel\n","#!lt --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"xvchA9gG7_po","executionInfo":{"status":"ok","timestamp":1734974363648,"user_tz":-60,"elapsed":33193,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}},"outputId":"a8d7ebc2-70bd-410f-cf2b-aa8b4b4e96c1"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Instalando pypdf2...\n","Instalando python-docx...\n","Instalando beautifulsoup4...\n","Instalando sentence-transformers...\n","Instalando faiss-cpu...\n","Instalando streamlit...\n","Instalando pyngrok...\n","Instalando google-colab-user-data...\n","Error instalando google-colab-user-data: Command '['/usr/bin/python3', '-m', 'pip', 'install', 'google-colab-user-data']' returned non-zero exit status 1.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","npm is already the newest version (8.5.1~ds-1).\n","nodejs is already the newest version (12.22.9~dfsg-1ubuntu3.6).\n","0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n","\u001b[K\u001b[?25h\n","changed 22 packages, and audited 23 packages in 2s\n","\n","3 packages are looking for funding\n","  run `npm fund` for details\n","\n","1 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerability\n","\n","To address all issues (including breaking changes), run:\n","  npm audit fix --force\n","\n","Run `npm audit` for details.\n","\n","Versiones de las librer√≠as instaladas:\n","pypdf2: 3.0.1\n","python-docx: 1.1.2\n","beautifulsoup4: 4.12.3\n","sentence-transformers: 3.3.1\n","faiss-cpu: 1.9.0.post1\n","streamlit: 1.41.1\n","pyngrok: 7.2.2\n","google-colab-user-data: No instalado\n","CPU times: user 300 ms, sys: 29 ms, total: 329 ms\n","Wall time: 32.9 s\n"]}]},{"cell_type":"markdown","source":["### ‚úîÔ∏èImportar las bibliotecas necesarias<a name=\"importar-las-bibliotecas-necesarias\"></a>\n","\n","- PyPDF2, docx y BeautifulSoup se usar√°n para extraer texto de distintos formatos de curr√≠culums.\n","- pandas ser√° √∫til para estructurar y analizar datos tabulares, como listas de candidatos y resultados.\n","- SentenceTransformer y FAISS se usar√°n para procesar el texto y permitir b√∫squedas sem√°nticas.\n","- Streamlit y pyngrok se usar√°n para crear y desplegar el chatbot.\n","- Matplotlib y Seaborn se usar√°n para gr√°ficos est√°ticos b√°sicos y an√°lisis de datos.\n","- Plotly ser√° √∫til para crear gr√°ficos interactivos directamente en Streamlit.\n","- Elige una de estas librer√≠as seg√∫n la necesidad de visualizaci√≥n."],"metadata":{"id":"9o0aa2RTWLkx"}},{"cell_type":"code","source":["# Importaci√≥n de librer√≠as necesarias para el proyecto\n","\n","# Manejo de archivos PDF\n","import PyPDF2  # Para extraer texto de archivos PDF\n","\n","# Manejo de archivos DOCX (Word)\n","import docx  # Para extraer texto de archivos .docx\n","\n","# Manejo de archivos HTML\n","from bs4 import BeautifulSoup  # Para procesar y extraer texto de archivos HTML\n","\n","# Manipulaci√≥n de datos estructurados\n","import pandas as pd  # Para manejar y procesar datos tabulares, como listas de candidatos\n","\n","# Creaci√≥n de embeddings y procesamiento de texto\n","from sentence_transformers import SentenceTransformer  # Para generar embeddings del texto\n","\n","# Almacenamiento vectorial\n","import faiss  # Para indexar y realizar b√∫squedas en embeddings\n","\n","# Interfaz gr√°fica\n","import streamlit as st  # Para crear una interfaz interactiva para el chatbot\n","\n","# Herramientas adicionales\n","import numpy as np  # Para manejo de arrays y c√°lculos matem√°ticos\n","import os  # Para manejar rutas y archivos en el sistema operativo\n","import re  # Para limpieza y procesamiento de texto\n","from typing import List  # Para especificar tipos en las funciones\n","\n","# Herramientas para pruebas locales y despliegue\n","from pyngrok import ngrok  # Para generar enlaces p√∫blicos al ejecutar Streamlit en Google Colab\n","\n","# Librer√≠as para visualizaci√≥n de datos\n","import matplotlib.pyplot as plt  # Para gr√°ficos b√°sicos y personalizables\n","import seaborn as sns  # Para gr√°ficos estad√≠sticos y m√°s estilizados\n","import plotly.express as px  # Para gr√°ficos interactivos en Streamlit\n","\n","# Google Colab\n","from google.colab import userdata\n"],"metadata":{"id":"oBPp57hTWL4i","executionInfo":{"status":"ok","timestamp":1734974363648,"user_tz":-60,"elapsed":24,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["### ‚úîÔ∏èConfigurar el entorno<a name=\"configurar-el-entorno\"></a>"],"metadata":{"id":"8zkxGo9VWNwo"}},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.options.display.float_format = '{:.8f}'.format\n","#pd.set_option('display.width', 1000)\n","\n","# Ajustar el ancho del contenedor de Jupyter/Colab:\n","from IPython.display import display, HTML\n","display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n","\n","\n","plt.style.use('ggplot')\n","\n","#plt.style.use('fivethirtyeight')\n","#plt.rcParams['figure.figsize'] = (10, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"S1JkCZ2hWN9D","executionInfo":{"status":"ok","timestamp":1734974363648,"user_tz":-60,"elapsed":24,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}},"outputId":"151aee5d-c7c5-42de-8714-ffcf67c690ae"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>.container { width:100% !important; }</style>"]},"metadata":{}}]},{"cell_type":"markdown","source":["### ‚úîÔ∏èConfigurar Colab - Seguridad<a name=\"configurar-drive\"></a>"],"metadata":{"id":"7Jo7_V57QJhH"}},{"cell_type":"code","source":["# PyNgrok\n","token_ngrok = userdata.get('TOKEN_NGROK')\n","#print(f\"Token de Ngrok: {token_ngrok}\")\n"],"metadata":{"id":"Yr_8gqI-QO71","executionInfo":{"status":"ok","timestamp":1734974364460,"user_tz":-60,"elapsed":834,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["### ‚úîÔ∏èConfigurar Drive<a name=\"configurar-drive\"></a>"],"metadata":{"id":"ty5-dMjDWOJe"}},{"cell_type":"markdown","source":["#### Montar el Google Drive en Google Colab"],"metadata":{"id":"FKDAdB3BmCQB"}},{"cell_type":"code","source":["%%time\n","# Montar el drive para obtener el csv\n","from google.colab import drive\n","\n","# Monta Google Drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDq0Y8-5WOUQ","executionInfo":{"status":"ok","timestamp":1734974365714,"user_tz":-60,"elapsed":1257,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}},"outputId":"3f1eb982-5072-4b4b-906f-6574aa2738ee"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","CPU times: user 17 ms, sys: 2.92 ms, total: 20 ms\n","Wall time: 1.19 s\n"]}]},{"cell_type":"markdown","source":["#### Crear la estructura de carpetas en el repositorio\n","Usa el siguiente c√≥digo en una celda de Python para crear la estructura de carpetas del proyecto dentro del repositorio clonado:"],"metadata":{"id":"uouhZPQ6nTrf"}},{"cell_type":"code","source":["# Configurar la estructura de carpetas\n","import os\n","\n","# Ruta completa a la carpeta del proyecto\n","project_path = '/content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV'\n","\n","# Estructura de carpetas\n","folders = [\n","    'data/input',\n","    'data/processed',\n","    'embeddings',\n","    'scripts/preprocess',\n","    'scripts/vectorization',\n","    'scripts/chatbot',\n","    'notebooks',\n","    'models',\n","    'logs'\n","]\n","\n","# Verificar si la carpeta existe\n","if os.path.exists(project_path):\n","    print(f\"Carpeta encontrada: {project_path}\")\n","    print(\"Archivos y carpetas:\", os.listdir(project_path))\n","else:\n","    print(f\"La carpeta no existe en la ruta: {project_path}\")\n","    print(\"Creando carpetas...\")\n","    # Crear las carpetas\n","    for folder in folders:\n","        os.makedirs(os.path.join(project_path, folder), exist_ok=True)\n","        print(f\"Carpeta creada: {os.path.join(project_path, folder)}\")\n","\n","print(\"\\nEstructura de carpetas creada exitosamente.\")\n","\n","# Si necesitas acceder a archivos dentro de esta carpeta, puedes usar\n","# os.path.join para manejar rutas, por ejemplo: %% [markdown] #### Crear la\n","# estructura de carpetas en el repositorio Usa el siguiente c√≥digo en una celda\n","# de Python para crear la estructura de carpetas del proyecto dentro del\n","# repositorio clonado: %% Estructura de carpetas\n","file_path = os.path.join(project_path, 'Chatbot_Analisis_CV.ipynb')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYZ0QryjyWcU","executionInfo":{"status":"ok","timestamp":1734974365714,"user_tz":-60,"elapsed":6,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}},"outputId":"90e7bc9d-ea9c-431a-ace2-1767cc7f9f55"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Carpeta encontrada: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV\n","Archivos y carpetas: ['README.md', 'notebooks', 'data', 'embeddings', 'scripts', 'models', 'logs', 'CVAnexo-Cronologico-ErikaSamaraAlvaresAngelim (1).pdf']\n","\n","Estructura de carpetas creada exitosamente.\n"]}]},{"cell_type":"markdown","source":["---\n","## Procesamiento de Documentos\n","- Permitir la carga de archivos en diferentes formatos.\n","- Extraer texto de los archivos cargados.\n","- Limpiar y estructurar el texto extra√≠do."],"metadata":{"id":"dX6x1wb1toHD"}},{"cell_type":"code","source":["# Funci√≥n para extraer texto de un archivo PDF\n","def extract_text_from_pdf(file):\n","    reader = PyPDF2.PdfReader(file)\n","    text = \"\"\n","    for page in reader.pages:\n","        text += page.extract_text()\n","    return text\n","\n","# Funci√≥n para extraer texto de un archivo DOCX\n","def extract_text_from_docx(file):\n","    doc = docx.Document(file)\n","    text = \"\"\n","    for paragraph in doc.paragraphs:\n","        text += paragraph.text + \"\\n\"\n","    return text\n","\n","# Funci√≥n para extraer texto de un archivo HTML\n","def extract_text_from_html(file):\n","    soup = BeautifulSoup(file, \"html.parser\")\n","    return soup.get_text()\n","\n","# Funci√≥n para extraer texto de un archivo TXT\n","def extract_text_from_txt(file):\n","    return file.read().decode('utf-8')\n","\n","# Funci√≥n para limpiar el texto\n","def clean_text(text):\n","    text = re.sub(r\"\\s+\", \" \", text)  # Reemplazar m√∫ltiples espacios por uno\n","    return text.strip()\n"],"metadata":{"id":"CwgHTHQL08OU","executionInfo":{"status":"ok","timestamp":1734974365714,"user_tz":-60,"elapsed":4,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["## Vectorizaci√≥n del Texto\n","\n","- Convertir el texto en representaciones vectoriales utilizando modelos de Hugging Face.\n","- Almacenar los embeddings utilizando FAISS."],"metadata":{"id":"ao2RVE3HzHEk"}},{"cell_type":"code","source":["# Cargar el modelo de Hugging Face\n","model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n","\n","# Funci√≥n para generar embeddings\n","def generate_embeddings(text):\n","    return model.encode(text)\n","\n","# Funci√≥n para crear un √≠ndice FAISS\n","def create_faiss_index(embeddings):\n","    dimension = embeddings.shape[1]\n","    index = faiss.IndexFlatL2(dimension)\n","    index.add(embeddings)\n","    return index\n"],"metadata":{"id":"BEkQfIfP1mF3","executionInfo":{"status":"ok","timestamp":1734974368311,"user_tz":-60,"elapsed":2601,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## Creaci√≥n del Chatbot\n","\n","- Implementar una interfaz gr√°fica usando Streamlit.\n","- Permitir al usuario escribir preguntas y obtener respuestas basadas en los embeddings.<br>\n","\n","---\n","\n","**Importante:**\n","- ***Instalaci√≥n de Dependencias:*** Aseg√∫rate de que todas las bibliotecas necesarias est√©n instaladas.\n","- ***Creaci√≥n del Archivo app.py:*** Este archivo contiene todo el c√≥digo de Streamlit.\n","- ***Ejecuci√≥n de Streamlit con pyngrok:*** pyngrok crea un t√∫nel que permite acceder a tu aplicaci√≥n Streamlit desde una URL p√∫blica.\n"],"metadata":{"id":"_gkNPvHlzYJW"}},{"cell_type":"markdown","source":["### Interfaz gr√°fica con Streamlit\n","Crea automaticamente el archivo app.py en Google Drive, en la siguiente ruta: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/scripts/chatbot/app.py"],"metadata":{"id":"EnQiyIrVLZLb"}},{"cell_type":"code","source":["# Ruta para guardar el archivo app.py en la carpeta scripts/chatbot/\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/scripts/chatbot/app.py\"\n","\n","# Escribir el archivo app.py en la ruta especificada\n","with open(file_path, \"w\") as f:\n","    f.write(\"\"\"\n","import streamlit as st\n","from PyPDF2 import PdfReader\n","from docx import Document\n","from bs4 import BeautifulSoup\n","from sentence_transformers import SentenceTransformer\n","import faiss\n","import numpy as np\n","import re\n","\n","# Funci√≥n para extraer texto de un archivo PDF\n","def extract_text_from_pdf(file):\n","    reader = PdfReader(file)\n","    text = \"\"\n","    for page in reader.pages:\n","        text += page.extract_text()\n","    return text\n","\n","# Funci√≥n para extraer texto de un archivo DOCX\n","def extract_text_from_docx(file):\n","    doc = Document(file)\n","    text = \"\"\n","    for paragraph in doc.paragraphs:\n","        text += paragraph.text + \"\\\\n\"\n","    return text\n","\n","# Funci√≥n para extraer texto de un archivo HTML\n","def extract_text_from_html(file):\n","    soup = BeautifulSoup(file, \"html.parser\")\n","    return soup.get_text()\n","\n","# Funci√≥n para extraer texto de un archivo TXT\n","def extract_text_from_txt(file):\n","    return file.read().decode('utf-8')\n","\n","# Funci√≥n para limpiar el texto\n","def clean_text(text):\n","    text = re.sub(r\"\\\\s+\", \" \", text)  # Reemplazar m√∫ltiples espacios por uno\n","    return text.strip()\n","\n","# Cargar el modelo de Hugging Face\n","model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n","\n","# Funci√≥n para generar embeddings\n","def generate_embeddings(text):\n","    return model.encode(text)\n","\n","# Funci√≥n para crear un √≠ndice FAISS\n","def create_faiss_index(embeddings):\n","    dimension = embeddings.shape[1]\n","    index = faiss.IndexFlatL2(dimension)\n","    index.add(embeddings)\n","    return index\n","\n","# Interfaz gr√°fica con Streamlit\n","st.title(\"Chatbot de An√°lisis de Curr√≠culum Vitae\")\n","uploaded_files = st.file_uploader(\"Sube tus documentos\", accept_multiple_files=True)\n","\n","if uploaded_files:\n","    # Combinar todo el texto de los archivos subidos\n","    all_text = \"\"\n","    for uploaded_file in uploaded_files:\n","        file_type = uploaded_file.type\n","        if file_type == \"application/pdf\":\n","            text = extract_text_from_pdf(uploaded_file)\n","        elif file_type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n","            text = extract_text_from_docx(uploaded_file)\n","        elif file_type == \"text/plain\":\n","            text = extract_text_from_txt(uploaded_file)\n","        elif file_type == \"text/html\":\n","            text = extract_text_from_html(uploaded_file)\n","        else:\n","            st.warning(f\"Formato de archivo no soportado: {uploaded_file.name}\")\n","            continue  # Saltar al siguiente archivo\n","\n","        # Limpiar y a√±adir texto\n","        text = clean_text(text)\n","        all_text += text + \"\\\\n\"\n","\n","    # Generar embeddings para el texto combinado\n","    embeddings = generate_embeddings([all_text])\n","\n","    # Crear √≠ndice FAISS\n","    index = create_faiss_index(embeddings)\n","\n","    # Mostrar texto extra√≠do\n","    st.text_area(\"Texto extra√≠do de los curr√≠culums:\", all_text, height=300)\n","\n","    # Permitir al usuario escribir preguntas\n","    question = st.text_input(\"Haz una pregunta sobre los curr√≠culums:\")\n","    if question:\n","        # Generar embedding de la pregunta\n","        query_embedding = generate_embeddings([question])\n","\n","        # Buscar en el √≠ndice FAISS\n","        distances, indices = index.search(np.array([query_embedding[0]]), k=5)\n","\n","        # Mostrar respuestas\n","        st.write(\"Respuestas encontradas:\")\n","        for i in indices[0]:\n","            st.write(all_text)\n","\"\"\")\n","\n","print(f\"Archivo app.py guardado en: {file_path}\")\n","\n","# Update ngrok and pyngrok\n","!pip install --upgrade pyngrok\n","!ngrok update\n","\n","\n","# Convertir token_ngrok a string si no es None\n","if token_ngrok is not None:\n","    token_ngrok = str(token_ngrok)\n","#print(token_ngrok)\n","\n","# Configurar pyngrok con tu authtoken\n","from pyngrok import ngrok\n","ngrok.set_auth_token(token_ngrok)\n","\n","\n","# 2. Ejecutar Streamlit\n","# Ejecutar la aplicaci√≥n Streamlit en el puerto 8501\n","!streamlit run /content/drive/MyDrive/Colab\\ Notebooks/Chatbot_Analisis_CV/scripts/chatbot/app.py --server.port 8501 &>/dev/null&\n","\n","\n","# 3. Iniciar ngrok\n","# Iniciar el t√∫nel ngrok\n","ngrok_process = ngrok.connect(addr=\"8501\", bind_tls=True)\n","\n","# Obtener la URL p√∫blica\n","public_url = ngrok_process.public_url\n","print(f\"Aplicaci√≥n p√∫blica: {public_url}\")\n","\n","\n","# 4. Verificaci√≥n de la Ejecuci√≥n de Streamlit\n","import requests\n","\n","# Intentar conectarse a la aplicaci√≥n Streamlit en el puerto 8501\n","try:\n","    response = requests.get(\"http://localhost:8501\")\n","    if response.status_code == 200:\n","        print(\"Streamlit est√° ejecut√°ndose correctamente en el puerto 8501.\")\n","    else:\n","        print(f\"Error al conectar a Streamlit: {response.status_code}\")\n","except requests.exceptions.ConnectionError:\n","    print(\"No se puede conectar a Streamlit en el puerto 8501. Aseg√∫rate de que la aplicaci√≥n est√© ejecut√°ndose.\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ktDdkgIZYVb2","executionInfo":{"status":"ok","timestamp":1734974382816,"user_tz":-60,"elapsed":14508,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}},"outputId":"5e1a0227-64ea-4545-bfb1-749e64417053"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Archivo app.py guardado en: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/scripts/chatbot/app.py\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.2)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n","\u001b[32mINFO\u001b[0m[12-23|17:19:41] no configuration paths supplied \n","\u001b[36mDBUG\u001b[0m[12-23|17:19:41] ngrok config file at legacy location does not exist \u001b[36mlegacy_path\u001b[0m=/root/.config/ngrok/ngrok.yml\n","\u001b[32mINFO\u001b[0m[12-23|17:19:41] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n","\u001b[32mINFO\u001b[0m[12-23|17:19:41] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n","No update available, this is the latest version.\n","2qckWQXFBzoi9jrpcOvmlSsZWLm_4bRfqkLrQY7WBG3AgVb8o\n","Aplicaci√≥n p√∫blica: https://e8c4-34-55-32-160.ngrok-free.app\n","Streamlit est√° ejecut√°ndose correctamente en el puerto 8501.\n"]}]},{"cell_type":"code","source":["# Ejecutar la aplicaci√≥n Streamlit\n","#!streamlit run /content/drive/MyDrive/Colab\\ Notebooks/Chatbot_Analisis_CV/scripts/chatbot/app.py &>/dev/null&\n"],"metadata":{"id":"CHyUKpdJcvZR","executionInfo":{"status":"ok","timestamp":1734972999646,"user_tz":-60,"elapsed":209,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"AtWkFYGWqhpl"}},{"cell_type":"code","source":["# Instalar LocalTunnel usando npm\n","!npm install -g localtunnel\n","\n","# Crear el archivo app.py en la ruta especificada\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/scripts/chatbot/app.py\"\n","with open(file_path, \"w\") as f:\n","    f.write(\"\"\"\n","import streamlit as st\n","from PyPDF2 import PdfReader\n","from docx import Document\n","from bs4 import BeautifulSoup\n","from sentence_transformers import SentenceTransformer\n","import faiss\n","import numpy as np\n","import re\n","\n","# Funci√≥n para extraer texto de un archivo PDF\n","def extract_text_from_pdf(file):\n","    reader = PdfReader(file)\n","    text = \"\"\n","    for page in reader.pages:\n","        text += page.extract_text()\n","    return text\n","\n","# Funci√≥n para extraer texto de un archivo DOCX\n","def extract_text_from_docx(file):\n","    doc = Document(file)\n","    text = \"\"\n","    for paragraph in doc.paragraphs:\n","        text += paragraph.text + \"\\\\n\"\n","    return text\n","\n","# Funci√≥n para extraer texto de un archivo HTML\n","def extract_text_from_html(file):\n","    soup = BeautifulSoup(file, \"html.parser\")\n","    return soup.get_text()\n","\n","# Funci√≥n para extraer texto de un archivo TXT\n","def extract_text_from_txt(file):\n","    return file.read().decode('utf-8')\n","\n","# Funci√≥n para limpiar el texto\n","def clean_text(text):\n","    text = re.sub(r\"\\\\s+\", \" \", text)  # Reemplazar m√∫ltiples espacios por uno\n","    return text.strip()\n","\n","# Cargar el modelo de Hugging Face\n","model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n","\n","# Funci√≥n para generar embeddings\n","def generate_embeddings(text):\n","    return model.encode(text)\n","\n","# Funci√≥n para crear un √≠ndice FAISS\n","def create_faiss_index(embeddings):\n","    dimension = embeddings.shape[1]\n","    index = faiss.IndexFlatL2(dimension)\n","    index.add(embeddings)\n","    return index\n","\n","# Interfaz gr√°fica con Streamlit\n","st.title(\"Chatbot de An√°lisis de Curr√≠culum Vitae\")\n","uploaded_files = st.file_uploader(\"Sube tus documentos\", accept_multiple_files=True)\n","\n","if uploaded_files:\n","    # Combinar todo el texto de los archivos subidos\n","    all_text = \"\"\n","    for uploaded_file in uploaded_files:\n","        file_type = uploaded_file.type\n","        if file_type == \"application/pdf\":\n","            text = extract_text_from_pdf(uploaded_file)\n","        elif file_type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n","            text = extract_text_from_docx(uploaded_file)\n","        elif file_type == \"text/plain\":\n","            text = extract_text_from_txt(uploaded_file)\n","        elif file_type == \"text/html\":\n","            text = extract_text_from_html(uploaded_file)\n","        else:\n","            st.warning(f\"Formato de archivo no soportado: {uploaded_file.name}\")\n","            continue  # Saltar al siguiente archivo\n","\n","        # Limpiar y a√±adir texto\n","        text = clean_text(text)\n","        all_text += text + \"\\\\n\"\n","\n","    # Generar embeddings para el texto combinado\n","    embeddings = generate_embeddings([all_text])\n","\n","    # Crear √≠ndice FAISS\n","    index = create_faiss_index(embeddings)\n","\n","    # Mostrar texto extra√≠do\n","    st.text_area(\"Texto extra√≠do de los curr√≠culums:\", all_text, height=300)\n","\n","    # Permitir al usuario escribir preguntas\n","    question = st.text_input(\"Haz una pregunta sobre los curr√≠culums:\")\n","    if question:\n","        # Generar embedding de la pregunta\n","        query_embedding = generate_embeddings([question])\n","\n","        # Buscar en el √≠ndice FAISS\n","        distances, indices = index.search(np.array([query_embedding[0]]), k=5)\n","\n","        # Mostrar respuestas\n","        st.write(\"Respuestas encontradas:\")\n","        for i in indices[0]:\n","            st.write(all_text)\n","\"\"\")\n","\n","print(f\"Archivo app.py guardado en: {file_path}\")\n","\n","# Ejecutar la aplicaci√≥n Streamlit en el puerto 8501\n","!streamlit run /content/drive/MyDrive/Colab\\ Notebooks/Chatbot_Analisis_CV/scripts/chatbot/app.py --server.port 8501 &>/dev/null&\n","\n","import requests\n","\n","# Obtener la contrase√±a del t√∫nel\n","response = requests.get(\"https://loca.lt/mytunnelpassword\")\n","password = response.text.strip()\n","print(f\"Contrase√±a del t√∫nel: {password}\")\n","\n","# Intentar conectarse a la aplicaci√≥n Streamlit en el puerto 8501\n","try:\n","    response = requests.get(\"http://localhost:8501\")\n","    if response.status_code == 200:\n","        print(\"Streamlit est√° ejecut√°ndose correctamente en el puerto 8501.\")\n","    else:\n","        print(f\"Error al conectar a Streamlit: {response.status_code}\")\n","except requests.exceptions.ConnectionError:\n","    print(\"No se puede conectar a Streamlit en el puerto 8501. Aseg√∫rate de que la aplicaci√≥n est√© ejecut√°ndose.\")\n","\n","# Iniciar LocalTunnel para crear un t√∫nel al puerto 8502\n","!lt --port 8502\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8d9-g7D8qh3w","outputId":"7529d9b2-3ad1-494c-8471-7fb51c2be102"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25h\n","changed 22 packages, and audited 23 packages in 2s\n","\n","3 packages are looking for funding\n","  run `npm fund` for details\n","\n","1 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerability\n","\n","To address all issues (including breaking changes), run:\n","  npm audit fix --force\n","\n","Run `npm audit` for details.\n","Archivo app.py guardado en: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/scripts/chatbot/app.py\n","Contrase√±a del t√∫nel: 34.55.32.160\n","No se puede conectar a Streamlit en el puerto 8501. Aseg√∫rate de que la aplicaci√≥n est√© ejecut√°ndose.\n","your url is: https://kind-flies-knock.loca.lt\n"]}]},{"cell_type":"markdown","source":["## Despliegue en Google Colab\n","\n","- Configurar Streamlit para ejecutarse dentro de Google Colab.\n","- Realizar pruebas funcionales y verificar el correcto funcionamiento del chatbot."],"metadata":{"id":"NihHBxHNzsZi"}},{"cell_type":"markdown","source":["### Pruebas\n","\n","Verificar que el chatbot funcione correctamente al cargar documentos y responder preguntas."],"metadata":{"id":"NIjUbTPbz4of"}},{"cell_type":"code","source":[],"metadata":{"id":"yBCtHlYWozva","executionInfo":{"status":"aborted","timestamp":1734968187975,"user_tz":-60,"elapsed":5,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualizaciones\n","\n","- ¬øC√≥mo integrar estos gr√°ficos en el proyecto?\n","- Decide qu√© datos quieres mostrar (distribuci√≥n de habilidades, experiencia, etc.).\n","- Crea una celda para cada gr√°fico con la librer√≠a que prefieras.\n","- Integra los gr√°ficos interactivos directamente en la interfaz de Streamlit para enriquecer la experiencia del usuario."],"metadata":{"id":"YFxX5hSto7HT"}},{"cell_type":"markdown","source":["### Matplotlib: Gr√°fico b√°sico de barras"],"metadata":{"id":"AmTtEcBKoz-4"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Ejemplo de datos: Distribuci√≥n de habilidades entre los candidatos\n","skills = ['Python', 'Data Analysis', 'Machine Learning', 'Project Management']\n","counts = [15, 20, 10, 8]\n","\n","# Crear un gr√°fico de barras\n","plt.figure(figsize=(8, 5))\n","plt.bar(skills, counts, color='skyblue')\n","plt.title('Distribuci√≥n de Habilidades entre los Candidatos')\n","plt.xlabel('Habilidades')\n","plt.ylabel('Cantidad de Candidatos')\n","plt.show()\n"],"metadata":{"id":"9OY39KRIo3Yc","executionInfo":{"status":"aborted","timestamp":1734968187975,"user_tz":-60,"elapsed":5,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Seaborn: Gr√°fico de viol√≠n para distribuci√≥n de experiencia"],"metadata":{"id":"3z7o6UIGpGUN"}},{"cell_type":"code","source":["import seaborn as sns\n","import pandas as pd\n","\n","# Ejemplo de datos: A√±os de experiencia de los candidatos\n","data = {'A√±os de Experiencia': [2, 3, 5, 7, 1, 4, 6, 2, 5, 3]}\n","df = pd.DataFrame(data)\n","\n","# Crear un gr√°fico de viol√≠n\n","plt.figure(figsize=(8, 5))\n","sns.violinplot(data=df, x='A√±os de Experiencia', color='lightcoral')\n","plt.title('Distribuci√≥n de A√±os de Experiencia entre los Candidatos')\n","plt.show()\n"],"metadata":{"id":"7PBPL64gpHbH","executionInfo":{"status":"aborted","timestamp":1734968187975,"user_tz":-60,"elapsed":5,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Plotly: Gr√°fico interactivo de pastel para la proporci√≥n de habilidades\n","\n","Si est√°s trabajando con Streamlit y deseas incluir gr√°ficos interactivos directamente en la interfaz:"],"metadata":{"id":"baGiLU3VpPes"}},{"cell_type":"code","source":["import streamlit as st\n","import plotly.express as px\n","\n","# Ejemplo de datos\n","skills = ['Python', 'Data Analysis', 'Machine Learning', 'Project Management']\n","counts = [15, 20, 10, 8]\n","\n","# Crear un gr√°fico de pastel interactivo\n","fig = px.pie(names=skills, values=counts, title='Distribuci√≥n de Habilidades entre los Candidatos')\n","\n","# Mostrar en Streamlit\n","st.plotly_chart(fig)\n"],"metadata":{"id":"xa6_RMI_pQpF","executionInfo":{"status":"aborted","timestamp":1734968187975,"user_tz":-60,"elapsed":4,"user":{"displayName":"Erika Alvares Analisis Datos","userId":"08290963828784602896"}}},"execution_count":null,"outputs":[]}]}