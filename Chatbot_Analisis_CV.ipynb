{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTochSmzLNsF8tgB4N5l1L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ea-analisisdatos/Chatbot_Analisis_CV/blob/main/Chatbot_Analisis_CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QQTUxJbRo2Nj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Proyecto: Chatbot de An√°lisis de Curr√≠culums**\n",
        "\n",
        "## **Descripci√≥n**\n",
        "El objetivo de este proyecto es desarrollar un chatbot que permita subir curr√≠culums en diferentes formatos (PDF, DOCX, TXT, HTML), analizar su contenido y responder a preguntas relacionadas con habilidades, experiencia, localizaci√≥n y otros detalles relevantes. Este proyecto usar√° herramientas de c√≥digo abierto y gratuitas para garantizar accesibilidad y aprendizaje."
      ],
      "metadata": {
        "id": "w253QQTHo6kH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Plan del Proyecto: Chatbot de An√°lisis de Curr√≠culums**\n",
        "\n",
        "#### **1. Requisitos del Proyecto**\n",
        "- **Entrada**: Subir curr√≠culums en formatos como PDF, DOCX, TXT o HTML.\n",
        "- **Procesamiento**: Extraer texto de los documentos y estructurar los datos relevantes.\n",
        "- **Salida**: Responder a preguntas basadas en las habilidades, experiencia, ubicaci√≥n y otros detalles de los candidatos.\n",
        "- **Almacenamiento**: Decidiremos entre bases de datos vectoriales (para b√∫squedas sem√°nticas) o bases relacionales.\n",
        "- **Tecnolog√≠as**:\n",
        "  - Preprocesamiento de documentos: `PyPDF2`, `python-docx`, `BeautifulSoup`.\n",
        "  - Modelo de lenguaje gratuito: `Hugging Face` (ej. `Llama 2` o `distilbert`).\n",
        "  - Framework para la aplicaci√≥n: `Streamlit` para despliegue en Google Colab.\n",
        "  - Almacenamiento vectorial: `FAISS` o `Chroma`.\n",
        "\n",
        "---\n",
        "\n",
        "## **Fases del Proyecto**\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Fases del Desarrollo**\n",
        "##### **Fase 1: Configuraci√≥n Inicial**\n",
        "1. Crear un entorno en **Google Colab**.\n",
        "2. Instalar las bibliotecas necesarias:\n",
        "   ```python\n",
        "   !pip install pypdf2 python-docx beautifulsoup4 sentence-transformers faiss-cpu streamlit\n",
        "   ```\n",
        "3. Crear un script que permita subir archivos y extraer texto.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Fase 2: Procesamiento de Documentos**\n",
        "1. **Subir archivos**:\n",
        "   - Permitir que los usuarios suban archivos PDF, DOCX, TXT o HTML.\n",
        "   - Usar el widget de carga de archivos en Streamlit para recibir documentos del usuario.\n",
        "2. **Extraer texto**:\n",
        "   - Usar `PyPDF2` para PDFs.\n",
        "   - Usar `python-docx` para DOCX.\n",
        "   - Usar `BeautifulSoup` para HTML.\n",
        "3. **Limpieza del texto**:\n",
        "   - Eliminar caracteres innecesarios y estructurar el texto para su an√°lisis.\n",
        "---\n",
        "\n",
        "##### **Fase 3: Vectorizaci√≥n del Texto**\n",
        "1. Usar un modelo preentrenado de Hugging Face (como `all-MiniLM-L6-v2`) para convertir el texto en **representaciones vectoriales**:\n",
        "   ```python\n",
        "   from sentence_transformers import SentenceTransformer\n",
        "   model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "   embeddings = model.encode([\"Texto del documento\"])\n",
        "   ```\n",
        "2. **Almacenamiento vectorial**:\n",
        "   - Almacenar los embeddings usando **FAISS** o **Chroma** para realizar b√∫squedas r√°pidas.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Fase 4: Creaci√≥n del Chatbot**\n",
        "1. Implementar una **interfaz gr√°fica** usando **Streamlit**:\n",
        "   - Permitir al usuario escribir preguntas relacionadas con los curr√≠culums.\n",
        "2. Consultar los embeddings y devolver respuestas basadas en las consultas.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Fase 5: Despliegue en Google Colab**\n",
        "1. Configurar Streamlit para ejecutarse dentro de Google Colab:\n",
        "   - Usar `pyngrok` para generar un enlace p√∫blico a la aplicaci√≥n.\n",
        "2. Realizar pruebas funcionales:\n",
        "  - Para verificar que el chatbot responde correctamente.\n",
        "  - Validar que las librer√≠as seleccionadas (como BeautifulSoup) son suficientes para procesar los documentos en HTML.\n",
        "\n",
        "---\n",
        "\n",
        "## **Herramientas Utilizadas**\n",
        "- **Preprocesamiento de documentos**:\n",
        "  - `PyPDF2`: Para extraer texto de PDFs.\n",
        "  - `python-docx`: Para extraer texto de archivos DOCX.\n",
        "  - `BeautifulSoup`: Para procesar HTML.\n",
        "- **Modelos de lenguaje**:\n",
        "  - `Hugging Face`: Modelos como `all-MiniLM-L6-v2`.\n",
        "- **Almacenamiento vectorial**:\n",
        "  - `FAISS` o `Chroma`.\n",
        "  - `FAISS`: Para b√∫squedas eficientes.\n",
        "- **Framework de desarrollo**:\n",
        "  - `Streamlit`: Para crear la interfaz del usuario.\n",
        "- **Entorno**:\n",
        "  - Google Colab como plataforma de desarrollo y pruebas.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Pr√≥ximos Pasos**\n",
        "\n",
        "1. Agregar funcionalidades avanzadas como:\n",
        "  - Uso de **bases de datos relacionales** para almacenar informaci√≥n adicional de los candidatos.\n",
        "  - **Clasificaci√≥n autom√°tica de candidatos** seg√∫n criterios predefinidos.\n",
        "2. Mejorar la capacidad del chatbot para realizar inferencias m√°s complejas.\n",
        "3. **Implementar m√©tricas de evaluaci√≥n** para medir la precisi√≥n de las respuestas del chatbot.\n",
        "4. Permitir subir **curr√≠culums en formato de imagen** (usando el Reconocimiento √ìptico de Caracteres (OCR)).\n",
        "5. Considerar qu√© otras funcionalidades agregar, como extracci√≥n de datos m√°s compleja (por ejemplo, **identificar autom√°ticamente a√±os de experiencia laboral o idiomas**).\n",
        "6. Optimizar el flujo de trabajo para un entorno de producci√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "## **Notas**\n",
        "\n",
        "Este proyecto es una introducci√≥n pr√°ctica al uso de herramientas de procesamiento de lenguaje natural, con √©nfasis en el aprendizaje y la accesibilidad.<br>\n",
        "\n",
        "Est√° dise√±ado para ser educativo y funcional, proporcionando una base s√≥lida para aprender sobre procesamiento de documentos, embeddings y construcci√≥n de chatbots. üòä"
      ],
      "metadata": {
        "id": "GQ-tcFJYreOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estructura de Carpetas del Proyecto `Chatbot_Analisis_CV`\n"
      ],
      "metadata": {
        "id": "-DDnncaLeuNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descripci√≥n de Carpetas\n",
        "\n",
        "```\n",
        "Chatbot_Analisis_CV/\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ data/                 # Para almacenar datasets y documentos de entrada\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ input/            # Archivos originales, como CVs en formatos PDF, DOCX, etc.\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ processed/        # Archivos procesados (texto extra√≠do, embeddings, etc.)\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ embeddings/           # Para almacenar archivos de embeddings generados\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ scripts/              # Scripts Python utilizados en el proyecto\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ preprocess/       # Scripts de preprocesamiento (extracci√≥n de texto, limpieza)\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ vectorization/    # Scripts para generar y manejar embeddings\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ chatbot/          # Scripts relacionados con la interfaz del chatbot\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ notebooks/            # Notebooks de desarrollo y an√°lisis\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ models/               # Modelos guardados (si es necesario entrenar alguno)\n",
        "‚îÇ\n",
        "‚îî‚îÄ‚îÄ logs/                 # Archivos de registro para guardar errores o procesos\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3JbpnZcsfL64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è **Configuraci√≥n del Ambiente e Importaci√≥n de Datos**<a name=\"configuracion-del-ambiente\"></a>\n",
        "\n",
        "En esta secci√≥n, se importan las bibliotecas necesarias para trabajar en el proyecto. Configuramos el entorno para visualizar todas las columnas de la tabla sin que la informaci√≥n se corte. Tambi√©n habilitamos el acceso a Google Drive para la lectura del archivo CSV y, finalmente, importamos y organizamos el conjunto de datos."
      ],
      "metadata": {
        "id": "N-PoUrMx7_P4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úîÔ∏èInstalar las bibliotecas necesarias<a name=\"instalar-las-bibliotecas-necesarias\"></a>"
      ],
      "metadata": {
        "id": "SrYNKOPZWcUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import sys\n",
        "import subprocess\n",
        "from importlib.metadata import version, PackageNotFoundError\n",
        "\n",
        "# Lista de librer√≠as requeridas para el proyecto\n",
        "required_libraries = [\n",
        "    'pypdf2',             # Para extraer texto de archivos PDF\n",
        "    'python-docx',        # Para procesar archivos DOCX\n",
        "    'beautifulsoup4',     # Para analizar archivos HTML\n",
        "    'sentence-transformers', # Para generar embeddings\n",
        "    'faiss-cpu',          # Para almacenamiento vectorial\n",
        "    'streamlit',          # Para la interfaz gr√°fica\n",
        "    'pyngrok'             # Para desplegar la aplicaci√≥n\n",
        "]\n",
        "\n",
        "# Funci√≥n para instalar librer√≠as de Python faltantes\n",
        "def install_libraries(libraries):\n",
        "    for lib in libraries:\n",
        "        try:\n",
        "            print(f\"Instalando {lib}...\")\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', lib])\n",
        "        except Exception as e:\n",
        "            print(f\"Error instalando {lib}: {e}\")\n",
        "\n",
        "# Instalar librer√≠as requeridas\n",
        "install_libraries(required_libraries)\n",
        "\n",
        "# Imprimir las versiones de las librer√≠as instaladas\n",
        "print(\"\\nVersiones de las librer√≠as instaladas:\")\n",
        "for lib in required_libraries:\n",
        "    try:\n",
        "        print(f\"{lib}: {version(lib.split('==')[0])}\")\n",
        "    except PackageNotFoundError:\n",
        "        print(f\"{lib}: No instalado\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvchA9gG7_po",
        "outputId": "e677606e-b061-4126-811f-6248c05587cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando pypdf2...\n",
            "Instalando python-docx...\n",
            "Instalando beautifulsoup4...\n",
            "Instalando sentence-transformers...\n",
            "Instalando faiss-cpu...\n",
            "Instalando streamlit...\n",
            "Instalando pyngrok...\n",
            "\n",
            "Versiones de las librer√≠as instaladas:\n",
            "pypdf2: 3.0.1\n",
            "python-docx: 1.1.2\n",
            "beautifulsoup4: 4.12.3\n",
            "sentence-transformers: 3.3.1\n",
            "faiss-cpu: 1.9.0.post1\n",
            "streamlit: 1.41.1\n",
            "pyngrok: 7.2.2\n",
            "CPU times: user 172 ms, sys: 29.6 ms, total: 202 ms\n",
            "Wall time: 28.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úîÔ∏èImportar las bibliotecas necesarias<a name=\"importar-las-bibliotecas-necesarias\"></a>\n",
        "\n",
        "- PyPDF2, docx y BeautifulSoup se usar√°n para extraer texto de distintos formatos de curr√≠culums.\n",
        "- pandas ser√° √∫til para estructurar y analizar datos tabulares, como listas de candidatos y resultados.\n",
        "- SentenceTransformer y FAISS se usar√°n para procesar el texto y permitir b√∫squedas sem√°nticas.\n",
        "- Streamlit y pyngrok se usar√°n para crear y desplegar el chatbot.\n",
        "- Matplotlib y Seaborn se usar√°n para gr√°ficos est√°ticos b√°sicos y an√°lisis de datos.\n",
        "- Plotly ser√° √∫til para crear gr√°ficos interactivos directamente en Streamlit.\n",
        "- Elige una de estas librer√≠as seg√∫n la necesidad de visualizaci√≥n."
      ],
      "metadata": {
        "id": "9o0aa2RTWLkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaci√≥n de librer√≠as necesarias para el proyecto\n",
        "\n",
        "# Manejo de archivos PDF\n",
        "import PyPDF2  # Para extraer texto de archivos PDF\n",
        "\n",
        "# Manejo de archivos DOCX (Word)\n",
        "import docx  # Para extraer texto de archivos .docx\n",
        "\n",
        "# Manejo de archivos HTML\n",
        "from bs4 import BeautifulSoup  # Para procesar y extraer texto de archivos HTML\n",
        "\n",
        "# Manipulaci√≥n de datos estructurados\n",
        "import pandas as pd  # Para manejar y procesar datos tabulares, como listas de candidatos\n",
        "\n",
        "# Creaci√≥n de embeddings y procesamiento de texto\n",
        "from sentence_transformers import SentenceTransformer  # Para generar embeddings del texto\n",
        "\n",
        "# Almacenamiento vectorial\n",
        "import faiss  # Para indexar y realizar b√∫squedas en embeddings\n",
        "\n",
        "# Interfaz gr√°fica\n",
        "import streamlit as st  # Para crear una interfaz interactiva para el chatbot\n",
        "\n",
        "# Herramientas adicionales\n",
        "import numpy as np  # Para manejo de arrays y c√°lculos matem√°ticos\n",
        "import os  # Para manejar rutas y archivos en el sistema operativo\n",
        "import re  # Para limpieza y procesamiento de texto\n",
        "from typing import List  # Para especificar tipos en las funciones\n",
        "\n",
        "# Herramientas para pruebas locales y despliegue\n",
        "from pyngrok import ngrok  # Para generar enlaces p√∫blicos al ejecutar Streamlit en Google Colab\n",
        "\n",
        "# Librer√≠as para visualizaci√≥n de datos\n",
        "import matplotlib.pyplot as plt  # Para gr√°ficos b√°sicos y personalizables\n",
        "import seaborn as sns  # Para gr√°ficos estad√≠sticos y m√°s estilizados\n",
        "import plotly.express as px  # Para gr√°ficos interactivos en Streamlit\n"
      ],
      "metadata": {
        "id": "oBPp57hTWL4i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úîÔ∏èConfigurar el entorno<a name=\"configurar-el-entorno\"></a>"
      ],
      "metadata": {
        "id": "8zkxGo9VWNwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.options.display.float_format = '{:.8f}'.format\n",
        "#pd.set_option('display.width', 1000)\n",
        "\n",
        "# Ajustar el ancho del contenedor de Jupyter/Colab:\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "#plt.style.use('fivethirtyeight')\n",
        "#plt.rcParams['figure.figsize'] = (10, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "S1JkCZ2hWN9D",
        "outputId": "92011295-fa8f-4a05-93a4-21bf87801ee0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úîÔ∏èConfigurar Drive<a name=\"configurar-drive\"></a>"
      ],
      "metadata": {
        "id": "ty5-dMjDWOJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Montar el Google Drive en Google Colab"
      ],
      "metadata": {
        "id": "FKDAdB3BmCQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Montar el Google Drive en Google Colab\n",
        "from google.colab import drive\n",
        "\n",
        "# Monta Google Drive en la ruta /content/drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta completa a la carpeta del proyecto\n",
        "project_path = '/content/drive/My Drive/Colab Notebooks/Chatbot_Analisis_CV'\n",
        "\n",
        "# Verificar si la carpeta existe\n",
        "import os\n",
        "if os.path.exists(project_path):\n",
        "    print(\"La carpeta del proyecto est√° accesible.\")\n",
        "    print(\"Archivos y carpetas:\", os.listdir(project_path))\n",
        "    print(f\"Carpeta encontrada: {project_path}\")\n",
        "else:\n",
        "    print(f\"La carpeta no existe. Por favor, verifica la ruta: {project_path}\")\n",
        "\n",
        "\n",
        "file_path = os.path.join(project_path, 'Chatbot_Analisis_CV.ipynb')\n",
        "print(f\"Ruta completa al archivo: {file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDq0Y8-5WOUQ",
        "outputId": "4562bbfc-ba05-4da7-f864-4811d7c3e285"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "La carpeta del proyecto est√° accesible.\n",
            "Archivos y carpetas: ['notebooks', 'data', 'embeddings', 'scripts', 'models', 'logs']\n",
            "Carpeta encontrada: /content/drive/My Drive/Colab Notebooks/Chatbot_Analisis_CV\n",
            "Ruta completa al archivo: /content/drive/My Drive/Colab Notebooks/Chatbot_Analisis_CV/Chatbot_Analisis_CV.ipynb\n",
            "CPU times: user 26.8 ms, sys: 3.65 ms, total: 30.4 ms\n",
            "Wall time: 2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Crear Estructura de Carpetas del Proyecto en Google Drive"
      ],
      "metadata": {
        "id": "hMducKuClU3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ruta base del proyecto\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV'\n",
        "\n",
        "# Lista de carpetas\n",
        "folders = [\n",
        "    'data/input',\n",
        "    'data/processed',\n",
        "    'embeddings',\n",
        "    'scripts/preprocess',\n",
        "    'scripts/vectorization',\n",
        "    'scripts/chatbot',\n",
        "    'notebooks',\n",
        "    'models',\n",
        "    'logs'\n",
        "]\n",
        "\n",
        "# Crear las carpetas\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(base_path, folder)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    print(f\"Carpeta creada o ya existente: {folder_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnM0Bj3okWMb",
        "outputId": "75b836de-a703-46f1-cf42-5ab20455fd2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carpeta creada o ya existente: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/data/input\n",
            "Carpeta creada o ya existente: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/data/processed\n",
            "Carpeta creada o ya existente: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/embeddings\n",
            "Carpeta creada o ya existente: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/scripts/preprocess\n",
            "Carpeta creada o ya existente: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/scripts/vectorization\n",
            "Carpeta creada o ya existente: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/scripts/chatbot\n",
            "Carpeta creada o ya existente: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/notebooks\n",
            "Carpeta creada o ya existente: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/models\n",
            "Carpeta creada o ya existente: /content/drive/MyDrive/Colab Notebooks/Chatbot_Analisis_CV/logs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Integraci√≥n con Github"
      ],
      "metadata": {
        "id": "_MU-3aCfnFg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Subir primero tus archivos y carpetas al repositorio vac√≠o\n",
        "Antes de clonar el repositorio, puedes subir todo lo que ya has creado (las carpetas y los archivos del proyecto) al repositorio en GitHub. As√≠ tendr√°s una sincronizaci√≥n inicial sin perder nada."
      ],
      "metadata": {
        "id": "wQ12Y9xEobOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura tus credenciales de Git\n",
        "!git config --global user.name \"ea-analisisdatos\"\n",
        "!git config --global user.email \"erikaalvares.analisisdatos@gmail.com\"\n"
      ],
      "metadata": {
        "id": "7_zbxsTftnrF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ruta del proyecto existente\n",
        "local_project_path = \"/content/drive/My Drive/Colab Notebooks/Chatbot_Analisis_CV\"\n",
        "\n",
        "# Aseg√∫rate de que est√°s en la carpeta del proyecto\n",
        "%cd $local_project_path\n",
        "\n",
        "# Inicializa un repositorio Git si no est√° inicializado\n",
        "!git init\n",
        "\n",
        "# Configura el repositorio remoto\n",
        "!git remote add origin https://github.com/ea-analisisdatos/Chatbot_Analisis_CV.git\n",
        "\n",
        "# Agrega todos los archivos al √°rea de staging\n",
        "!git add .\n",
        "\n",
        "# Realiza un commit inicial\n",
        "!git commit -m \"Sincronizar proyecto existente con repositorio remoto\"\n",
        "\n",
        "# Configura la rama principal como `main`\n",
        "!git branch -M main\n",
        "\n",
        "# Sube los cambios al repositorio remoto\n",
        "!git push -u origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7lcDLiCxnkU",
        "outputId": "eff9a1fc-051c-4f24-e440-5834d7aab43a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/Chatbot_Analisis_CV'\n",
            "/content\n",
            "Reinitialized existing Git repository in /content/.git/\n",
            "error: remote origin already exists.\n",
            "On branch main\n",
            "nothing to commit, working tree clean\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura tu repositorio remoto en Colab con los comandos de git\n",
        "\n",
        "# Inicializar un repositorio local (si no est√° inicializado)\n",
        "!git init\n",
        "\n",
        "# Configura tu repositorio remoto\n",
        "!git remote add origin https://github.com/ea-analisisdatos/Chatbot_Analisis_CV.git\n",
        "\n",
        "# Agrega todos los archivos y carpetas al √°rea de staging\n",
        "!git add .\n",
        "\n",
        "# Crea un commit inicial\n",
        "!git commit -m \"Subir estructura inicial del proyecto desde Google Colab\"\n",
        "\n",
        "# Sube los archivos al repositorio remoto\n",
        "!git branch -M main  # Aseg√∫rate de usar la rama correcta\n",
        "!git push -u origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3s6DUA8oj5j",
        "outputId": "338ac67c-25b0-4d33-d99c-91610221b56d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n",
            "error: remote origin already exists.\n",
            "warning: adding embedded git repository: Chatbot_Analisis_CV\n",
            "\u001b[33mhint: You've added another git repository inside your current repository.\u001b[m\n",
            "\u001b[33mhint: Clones of the outer repository will not contain the contents of\u001b[m\n",
            "\u001b[33mhint: the embedded repository and will not know how to obtain it.\u001b[m\n",
            "\u001b[33mhint: If you meant to add a submodule, use:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit submodule add <url> Chatbot_Analisis_CV\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: If you added this path by mistake, you can remove it from the\u001b[m\n",
            "\u001b[33mhint: index with:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit rm --cached Chatbot_Analisis_CV\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: See \"git help submodule\" for more information.\u001b[m\n",
            "[main (root-commit) afb3af6] Subir estructura inicial del proyecto desde Google Colab\n",
            " 22 files changed, 51024 insertions(+)\n",
            " create mode 100644 .config/.last_opt_in_prompt.yaml\n",
            " create mode 100644 .config/.last_survey_prompt.yaml\n",
            " create mode 100644 .config/.last_update_check.json\n",
            " create mode 100644 .config/active_config\n",
            " create mode 100644 .config/config_sentinel\n",
            " create mode 100644 .config/configurations/config_default\n",
            " create mode 100644 .config/default_configs.db\n",
            " create mode 100644 .config/gce\n",
            " create mode 100644 .config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db\n",
            " create mode 100644 .config/logs/2024.12.19/14.19.43.316528.log\n",
            " create mode 100644 .config/logs/2024.12.19/14.20.05.781718.log\n",
            " create mode 100644 .config/logs/2024.12.19/14.20.16.940511.log\n",
            " create mode 100644 .config/logs/2024.12.19/14.20.18.151587.log\n",
            " create mode 100644 .config/logs/2024.12.19/14.20.29.520330.log\n",
            " create mode 100644 .config/logs/2024.12.19/14.20.30.129972.log\n",
            " create mode 160000 Chatbot_Analisis_CV\n",
            " create mode 100755 sample_data/README.md\n",
            " create mode 100755 sample_data/anscombe.json\n",
            " create mode 100644 sample_data/california_housing_test.csv\n",
            " create mode 100644 sample_data/california_housing_train.csv\n",
            " create mode 100644 sample_data/mnist_test.csv\n",
            " create mode 100644 sample_data/mnist_train_small.csv\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clonar el repositorio y fusionar los archivos existentes\n",
        "Si decides clonar el repositorio vac√≠o antes de subir tus carpetas, debes fusionar tus archivos locales con los del repositorio para evitar sobrescribir."
      ],
      "metadata": {
        "id": "4pX6KMZboybn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clona el repositorio vac√≠o:\n",
        "!git clone https://github.com/ea-analisisdatos/Chatbot_Analisis_CV.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdR9iiHro5Hv",
        "outputId": "3d7e9dfe-59b9-42a2-aa29-5febbd262881"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Chatbot_Analisis_CV'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "Receiving objects: 100% (4/4), done.\n",
            "remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la conexi√≥n con el repositorio remoto:\n",
        "!git remote -v\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37GAcBITt4ZZ",
        "outputId": "7bcbde4b-154f-473e-eb87-67e2956c4712"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "origin\thttps://github.com/ea-analisisdatos/Chatbot_Analisis_CV.git (fetch)\n",
            "origin\thttps://github.com/ea-analisisdatos/Chatbot_Analisis_CV.git (push)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia las carpetas y archivos existentes de tu proyecto en Colab al repositorio clonado:\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Rutas locales en Google Drive\n",
        "local_project_path = \"/content/drive/My Drive/Colab Notebooks/Chatbot_Analisis_CV\"\n",
        "\n",
        "# Clonar el repositorio en la misma ubicaci√≥n donde ya est√°s trabajando\n",
        "cloned_repo_path = \"/content/drive/My Drive/Colab Notebooks/Chatbot_Analisis_CV\"\n",
        "\n",
        "# Clonar el repositorio si no existe\n",
        "import os\n",
        "if not os.path.exists(cloned_repo_path):  # Si la carpeta a√∫n no existe\n",
        "    !git clone https://github.com/ea-analisisdatos/Chatbot_Analisis_CV.git $cloned_repo_path\n",
        "else:\n",
        "    print(f\"El repositorio ya est√° clonado en: {cloned_repo_path}\")\n",
        "\n",
        "# Verificar archivos en la carpeta clonada\n",
        "os.listdir(cloned_repo_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uglcS6-wpB-W",
        "outputId": "9b0662cc-b842-49f7-deca-40504e9d993e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: Too many arguments.\n",
            "\n",
            "usage: git clone [<options>] [--] <repo> [<dir>]\n",
            "\n",
            "    -v, --verbose         be more verbose\n",
            "    -q, --quiet           be more quiet\n",
            "    --progress            force progress reporting\n",
            "    --reject-shallow      don't clone shallow repository\n",
            "    -n, --no-checkout     don't create a checkout\n",
            "    --bare                create a bare repository\n",
            "    --mirror              create a mirror repository (implies bare)\n",
            "    -l, --local           to clone from a local repository\n",
            "    --no-hardlinks        don't use local hardlinks, always copy\n",
            "    -s, --shared          setup as shared repository\n",
            "    --recurse-submodules[=<pathspec>]\n",
            "                          initialize submodules in the clone\n",
            "    --recursive ...       alias of --recurse-submodules\n",
            "    -j, --jobs <n>        number of submodules cloned in parallel\n",
            "    --template <template-directory>\n",
            "                          directory from which templates will be used\n",
            "    --reference <repo>    reference repository\n",
            "    --reference-if-able <repo>\n",
            "                          reference repository\n",
            "    --dissociate          use --reference only while cloning\n",
            "    -o, --origin <name>   use <name> instead of 'origin' to track upstream\n",
            "    -b, --branch <branch>\n",
            "                          checkout <branch> instead of the remote's HEAD\n",
            "    -u, --upload-pack <path>\n",
            "                          path to git-upload-pack on the remote\n",
            "    --depth <depth>       create a shallow clone of that depth\n",
            "    --shallow-since <time>\n",
            "                          create a shallow clone since a specific time\n",
            "    --shallow-exclude <revision>\n",
            "                          deepen history of shallow clone, excluding rev\n",
            "    --single-branch       clone only one branch, HEAD or --branch\n",
            "    --no-tags             don't clone any tags, and make later fetches not to follow them\n",
            "    --shallow-submodules  any cloned submodules will be shallow\n",
            "    --separate-git-dir <gitdir>\n",
            "                          separate git dir from working tree\n",
            "    -c, --config <key=value>\n",
            "                          set config inside the new repository\n",
            "    --server-option <server-specific>\n",
            "                          option to transmit\n",
            "    -4, --ipv4            use IPv4 addresses only\n",
            "    -6, --ipv6            use IPv6 addresses only\n",
            "    --filter <args>       object filtering\n",
            "    --remote-submodules   any cloned submodules will use their remote-tracking branch\n",
            "    --sparse              initialize sparse-checkout file to include only files at root\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/Chatbot_Analisis_CV'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cb0ab6dbb88a>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Verificar archivos en la carpeta clonada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloned_repo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/Chatbot_Analisis_CV'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sube los cambios al repositorio:\n",
        "%cd /content/drive/My Drive/Colab Notebooks/Chatbot_Analisis_CV\n",
        "!git add .\n",
        "!git commit -m \"Subir estructura inicial del proyecto desde Google Colab\"\n",
        "# !git branch -M main  # Renombrar la rama a 'main'\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "id": "lqdL6dvJpN1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Crear la estructura de carpetas en el repositorio\n",
        "Usa el siguiente c√≥digo en una celda de Python para crear la estructura de carpetas del proyecto dentro del repositorio clonado:"
      ],
      "metadata": {
        "id": "uouhZPQ6nTrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ruta del repositorio clonado\n",
        "repo_path = \"/content/drive/My Drive/Colab Notebooks/Chatbot_Analisis_CV\"\n",
        "\n",
        "# Estructura de carpetas\n",
        "folders = [\n",
        "    \"data/input\", \"data/processed\", \"embeddings\",\n",
        "    \"scripts/preprocess\", \"scripts/vectorization\", \"scripts/chatbot\",\n",
        "    \"notebooks\", \"models\", \"logs\"\n",
        "]\n",
        "\n",
        "# Crear las carpetas\n",
        "for folder in folders:\n",
        "    os.makedirs(os.path.join(repo_path, folder), exist_ok=True)\n",
        "    print(f\"Carpeta creada: {os.path.join(repo_path, folder)}\")\n"
      ],
      "metadata": {
        "id": "7oMhdYCWnI_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Subir los cambios al repositorio en GitHub\n",
        "\n",
        "Usa los siguientes comandos para agregar, hacer commit y subir las carpetas al repositorio.\n",
        "\n",
        "- Reemplaza tu_usuario y tu_email con tus credenciales de GitHub.\n",
        "- Si tu rama principal no se llama main, c√°mbiala por el nombre correcto."
      ],
      "metadata": {
        "id": "cQJEm1_Dnetu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura tus credenciales de Git\n",
        "!git config --global user.name \"ea-analisisdatos\"\n",
        "!git config --global user.email \"erikaalvares.analisisdatos@gmail.com\"\n",
        "\n",
        "# Agrega los archivos al √°rea de staging\n",
        "!git add .\n",
        "\n",
        "# Crea un commit con un mensaje\n",
        "!git commit -m \"A√±adir estructura inicial de carpetas\"\n",
        "\n",
        "# Sube los cambios al repositorio\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "id": "GW7vXTDpnlZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Verificar el estado del repositorio\n",
        "\n",
        "Puedes verificar el estado del repositorio para confirmar qu√© archivos est√°n listos para ser subidos o si hay conflictos."
      ],
      "metadata": {
        "id": "AP50sceJnyxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git status\n"
      ],
      "metadata": {
        "id": "pgMWjHNsn3a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Procesamiento de Documentos"
      ],
      "metadata": {
        "id": "dX6x1wb1toHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subir archivos\n",
        "\n",
        "Usar el widget de carga de archivos en Streamlit para recibir documentos del usuario."
      ],
      "metadata": {
        "id": "mlHtyzReyGcP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzNhCcg8osVT"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "\n",
        "uploaded_files = st.file_uploader(\"Sube tus documentos\", accept_multiple_files=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extraer texto\n",
        "Procesar los documentos dependiendo del formato"
      ],
      "metadata": {
        "id": "buO7Qr5RyWkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(file):\n",
        "    reader = PdfReader(file)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "Jn33jtxsyg1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DOCX\n",
        "from docx import Document\n",
        "\n",
        "def extract_text_from_docx(file):\n",
        "    doc = Document(file)\n",
        "    text = \"\"\n",
        "    for paragraph in doc.paragraphs:\n",
        "        text += paragraph.text + \"\\n\"\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "utLFjxAuyjjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HTML\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_text_from_html(file):\n",
        "    soup = BeautifulSoup(file, \"html.parser\")\n",
        "    return soup.get_text()\n"
      ],
      "metadata": {
        "id": "6Y10HvvMyn2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TXT\n",
        "def extract_text_from_txt(file):\n",
        "    return file.read().decode(\"utf-8\")\n"
      ],
      "metadata": {
        "id": "LR79x6fZysy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limpieza del texto\n",
        "Eliminar caracteres innecesarios como saltos de l√≠nea repetidos o espacios en blanco."
      ],
      "metadata": {
        "id": "v_wmvO8yy3ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # Reemplazar m√∫ltiples espacios por uno\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "KVBPBPh5zEHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorizaci√≥n del Texto"
      ],
      "metadata": {
        "id": "ao2RVE3HzHEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convertir texto en embeddings\n",
        "\n",
        "Usar un modelo de Hugging Face (como all-MiniLM-L6-v2) para transformar el texto en representaciones vectoriales."
      ],
      "metadata": {
        "id": "LVglg1zEzKbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "# embeddings = model.encode([\"texto del documento\"])\n",
        "\n",
        "def generate_embeddings(text):\n",
        "    return model.encode(text)\n"
      ],
      "metadata": {
        "id": "Kfpslw8lzOH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Almacenamiento vectorial\n",
        "\n",
        "Usar **FAISS** para almacenar y buscar en los embeddings generados."
      ],
      "metadata": {
        "id": "ktJTBAUmzQt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "def create_faiss_index(embeddings):\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "    return index\n"
      ],
      "metadata": {
        "id": "9n2h6KZGzVRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creaci√≥n del Chatbot\n",
        "\n",
        "***Implementar una interfaz gr√°fica usando Streamlit:***<br>\n",
        "- Permitir al usuario escribir preguntas relacionadas con los curr√≠culums.\n",
        "- Consultar los embeddings y devolver respuestas basadas en las consultas."
      ],
      "metadata": {
        "id": "_gkNPvHlzYJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interfaz gr√°fica con Streamlit\n",
        "\n",
        "Crear una interfaz para que los usuarios interact√∫en con el chatbot."
      ],
      "metadata": {
        "id": "n_oud8Ngzciv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "\n",
        "st.title(\"Chatbot de An√°lisis de Curr√≠culums\")\n",
        "question = st.text_input(\"Haz una pregunta sobre los curr√≠culums:\")\n"
      ],
      "metadata": {
        "id": "ks-DLhDazhJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consulta de embeddings\n",
        "Permitir que los usuarios hagan preguntas y obtener respuestas relevantes de los documentos."
      ],
      "metadata": {
        "id": "eKgGa50xzjOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_in_index(index, query_embedding, k=5):\n",
        "    distances, indices = index.search(np.array([query_embedding]), k)\n",
        "    return indices\n"
      ],
      "metadata": {
        "id": "KTC_ZakpzpGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Despliegue en Google Colab\n",
        "\n",
        "***Configurar Streamlit para ejecutarse dentro de Google Colab:***\n",
        "- Usar pyngrok para generar un enlace p√∫blico a la aplicaci√≥n."
      ],
      "metadata": {
        "id": "NihHBxHNzsZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurar Streamlit con pyngrok\n",
        "\n",
        "Ejecutar la aplicaci√≥n Streamlit y exponerla a trav√©s de un enlace p√∫blico."
      ],
      "metadata": {
        "id": "CSS7MKQ4zvEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "def start_streamlit():\n",
        "    public_url = ngrok.connect(port='8501')\n",
        "    print(\"La aplicaci√≥n est√° disponible en:\", public_url)\n"
      ],
      "metadata": {
        "id": "0bMGdHT9zzjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pruebas\n",
        "\n",
        "Verificar que el chatbot funcione correctamente al cargar documentos y responder preguntas."
      ],
      "metadata": {
        "id": "NIjUbTPbz4of"
      }
    }
  ]
}